{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.50  Python-3.9.13 torch-2.5.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3080 Ti, 12287MiB)\n",
      "Setup complete  (16 CPUs, 31.9 GB RAM, 182.2/265.6 GB disk)\n"
     ]
    }
   ],
   "source": [
    "#%pip install git+https://github.com/ultralytics/ultralytics\n",
    "import ultralytics\n",
    "ultralytics.checks()\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.50  Python-3.9.13 torch-2.5.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3080 Ti, 12287MiB)\n",
      "YOLO11n summary (fused): 238 layers, 2,583,907 parameters, 0 gradients, 6.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning G:\\Shahadath\\Dataset\\test\\labels.cache... 2033 images, 1 backgrounds, 0 corrupt: 100%|██████████| 2033/2033 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 128/128 [00:11<00:00, 10.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2033       4718       0.73      0.529      0.558      0.358\n",
      "           boneanomaly         23         32      0.324      0.219      0.202     0.0674\n",
      "            bonelesion          6          7          1       0.24      0.367      0.207\n",
      "           foreignbody          1          1          1          0          0          0\n",
      "              fracture       1346       1799      0.874      0.892      0.935      0.571\n",
      "                 metal         66         73      0.859      0.986      0.984      0.837\n",
      "    periostealreaction        223        351      0.608      0.632      0.639      0.292\n",
      "          pronatorsign         42         42      0.513      0.357      0.509      0.299\n",
      "            softtissue         50         53       0.43      0.455      0.391       0.21\n",
      "                  text       2028       2360      0.959      0.981      0.991      0.739\n",
      "Speed: 0.1ms preprocess, 1.2ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val8\u001b[0m\n",
      "Ultralytics 8.3.50  Python-3.9.13 torch-2.5.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3080 Ti, 12287MiB)\n",
      "YOLO11s summary (fused): 238 layers, 9,416,283 parameters, 0 gradients, 21.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning G:\\Shahadath\\Dataset\\test\\labels.cache... 2033 images, 1 backgrounds, 0 corrupt: 100%|██████████| 2033/2033 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 128/128 [00:12<00:00, 10.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2033       4718      0.762      0.644       0.69      0.452\n",
      "           boneanomaly         23         32      0.291      0.156      0.141     0.0594\n",
      "            bonelesion          6          7          1      0.845      0.858      0.594\n",
      "           foreignbody          1          1          1          0      0.497      0.254\n",
      "              fracture       1346       1799      0.887      0.917      0.951      0.609\n",
      "                 metal         66         73      0.919          1      0.986      0.851\n",
      "    periostealreaction        223        351      0.683      0.681      0.718      0.351\n",
      "          pronatorsign         42         42      0.564      0.833      0.666      0.389\n",
      "            softtissue         50         53      0.555      0.377      0.398      0.216\n",
      "                  text       2028       2360      0.964      0.982      0.992      0.746\n",
      "Speed: 0.1ms preprocess, 1.6ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val9\u001b[0m\n",
      "Ultralytics 8.3.50  Python-3.9.13 torch-2.5.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3080 Ti, 12287MiB)\n",
      "YOLO11m summary (fused): 303 layers, 20,036,971 parameters, 0 gradients, 67.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning G:\\Shahadath\\Dataset\\test\\labels.cache... 2033 images, 1 backgrounds, 0 corrupt: 100%|██████████| 2033/2033 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 128/128 [00:15<00:00,  8.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2033       4718      0.796      0.706      0.816      0.554\n",
      "           boneanomaly         23         32      0.635        0.5      0.466      0.244\n",
      "            bonelesion          6          7       0.78      0.714      0.832      0.569\n",
      "           foreignbody          1          1          1          0      0.995      0.597\n",
      "              fracture       1346       1799      0.925      0.959      0.978      0.671\n",
      "                 metal         66         73       0.97          1      0.995      0.899\n",
      "    periostealreaction        223        351      0.735      0.663      0.763      0.418\n",
      "          pronatorsign         42         42       0.61      0.856      0.771      0.502\n",
      "            softtissue         50         53       0.54      0.679      0.548      0.333\n",
      "                  text       2028       2360      0.973      0.983      0.993      0.756\n",
      "Speed: 0.1ms preprocess, 3.3ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val10\u001b[0m\n",
      "\n",
      "Model                         Precision Recall    mAP@50    mAP@50-95      Params(M) FLOPs(B)  Inference Time (ms)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Model_N_best.pt.pt            0.73      0.529     0.558     0.358          2.584     5.168     20.85\n",
      "Model_S_best.pt.pt            0.762     0.644     0.69      0.452          9.416     18.833    21.01\n",
      "Model_M_best.pt               0.796     0.706     0.816     0.554          20.037    40.074    22.58\n"
     ]
    }
   ],
   "source": [
    "   import time\n",
    "import torch\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Define the models and their paths\n",
    "models_info = [\n",
    "    {\n",
    "        \"name\": \"Model_N_best.pt.pt\",\n",
    "        \"weights_path\": \"Model/Model_N_best.pt\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Model_S_best.pt.pt\",\n",
    "        \"weights_path\": \"Model/Model_S_best.pt\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Model_M_best.pt\",\n",
    "        \"weights_path\": \"Model/Model_M_best.pt\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Path to the test images\n",
    "test_images_dir = 'Dataset/test/images'\n",
    "\n",
    "# Path to data.yaml\n",
    "data_yaml_path = 'data.yaml'\n",
    "\n",
    "\n",
    "# Get list of image files in the test directory\n",
    "img_files = [f for f in os.listdir(test_images_dir) if f.endswith(('png', 'jpg', 'jpeg'))]\n",
    "num_images = len(img_files)\n",
    "\n",
    "# Initialize a list to store results\n",
    "results = []\n",
    "\n",
    "# Iterate over each model and evaluate\n",
    "for model_info in models_info:\n",
    "    model_name = model_info[\"name\"]\n",
    "    weights_path = model_info[\"weights_path\"]\n",
    "    \n",
    "    # Load the YOLO model\n",
    "    model = YOLO(weights_path)\n",
    "    \n",
    "    # -------------------- Model Evaluation --------------------\n",
    "    # Evaluate the model on the test set\n",
    "    metrics = model.val(data=data_yaml_path, split=\"test\", batch=16, imgsz=640)\n",
    "\n",
    "    # Extract metrics safely\n",
    "    try:\n",
    "        precision = metrics.box.p.mean()  # Mean Precision\n",
    "        recall = metrics.box.r.mean()     # Mean Recall\n",
    "        map50 = metrics.box.map50.mean()  # Mean mAP@50\n",
    "        map = metrics.box.map.mean()      # Mean mAP@50-95\n",
    "    except AttributeError:\n",
    "        print(f\"Error extracting metrics for {model_name}. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    # -------------------- Inference Time Calculation --------------------\n",
    "    total_time = 0\n",
    "\n",
    "    # Loop through each image file and perform inference\n",
    "    for img_file in img_files:\n",
    "        img_path = os.path.join(test_images_dir, img_file)\n",
    "\n",
    "        # Suppress output from YOLO during inference\n",
    "        with torch.no_grad():\n",
    "            start_time = time.time()\n",
    "            _ = model(img_path, verbose=False)  # Perform inference with verbose=False\n",
    "            inference_time = time.time() - start_time\n",
    "\n",
    "        # Accumulate the inference time in milliseconds\n",
    "        total_time += inference_time * 1000  # Convert to milliseconds\n",
    "\n",
    "    # Calculate the average inference time in milliseconds\n",
    "    average_inference_time = total_time / num_images\n",
    "\n",
    "    # -------------------- Model Parameters and FLOPs --------------------\n",
    "    # Extracting model parameters (in millions)\n",
    "    params = sum(p.numel() for p in model.parameters()) / 1e6  # In millions\n",
    "\n",
    "    # Assuming the model's FLOPs is roughly related to the number of parameters (this is an approximation)\n",
    "    # Using a simple heuristic: FLOPs (billions) ~ Parameters (millions) * 2 (simplified estimate)\n",
    "    flops = params * 2  # This is a rough approximation and may differ based on the architecture\n",
    "\n",
    "    # Append the results for this model\n",
    "    results.append({\n",
    "        \"Model\": model_name,\n",
    "        \"Precision\": round(precision, 3),\n",
    "        \"Recall\": round(recall, 3),\n",
    "        \"mAP@50\": round(map50, 3),\n",
    "        \"mAP@50-95\": round(map, 3),\n",
    "        \"Params(M)\": round(params, 3),\n",
    "        \"FLOPs(B)\": round(flops, 3),\n",
    "        \"Inference Time (ms)\": round(average_inference_time, 2)\n",
    "    })\n",
    "\n",
    "# Print the results table\n",
    "print(f\"\\n{'Model':<30}{'Precision':<10}{'Recall':<10}{'mAP@50':<10}{'mAP@50-95':<15}{'Params(M)':<10}{'FLOPs(B)':<10}{'Inference Time (ms)'}\")\n",
    "print(\"-\" * 100)\n",
    "for result in results:\n",
    "    print(f\"{result['Model']:<30}{result['Precision']:<10}{result['Recall']:<10}{result['mAP@50']:<10}{result['mAP@50-95']:<15}{result['Params(M)']:<10}{result['FLOPs(B)']:<10}{result['Inference Time (ms)']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.50  Python-3.9.13 torch-2.5.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3080 Ti, 12287MiB)\n",
      "YOLO11m summary (fused): 303 layers, 20,036,971 parameters, 0 gradients, 67.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning G:\\Shahadath\\Dataset\\test\\labels.cache... 2033 images, 1 backgrounds, 0 corrupt: 100%|██████████| 2033/2033 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 128/128 [00:15<00:00,  8.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2033       4718      0.539      0.361      0.449      0.249\n",
      "           boneanomaly         23         32          0          0    0.00383    0.00121\n",
      "            bonelesion          6          7          1          0      0.423      0.248\n",
      "           foreignbody          1          1          0          0          0          0\n",
      "              fracture       1346       1799      0.871      0.856       0.91      0.541\n",
      "                 metal         66         73       0.55       0.74      0.717      0.302\n",
      "    periostealreaction        223        351      0.521      0.507      0.519      0.196\n",
      "          pronatorsign         42         42      0.558      0.151      0.345      0.161\n",
      "            softtissue         50         53      0.382     0.0189      0.135     0.0541\n",
      "                  text       2028       2360      0.968      0.975      0.987      0.737\n",
      "Speed: 0.1ms preprocess, 3.3ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val11\u001b[0m\n",
      "Ultralytics 8.3.50  Python-3.9.13 torch-2.5.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3080 Ti, 12287MiB)\n",
      "YOLO11m summary (fused): 303 layers, 20,036,971 parameters, 0 gradients, 67.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning G:\\Shahadath\\Dataset\\test\\labels.cache... 2033 images, 1 backgrounds, 0 corrupt: 100%|██████████| 2033/2033 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 128/128 [00:15<00:00,  8.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2033       4718      0.691      0.425      0.492      0.258\n",
      "           boneanomaly         23         32      0.494      0.125      0.141     0.0337\n",
      "            bonelesion          6          7          1          0      0.359      0.131\n",
      "           foreignbody          1          1          1          0     0.0474     0.0237\n",
      "              fracture       1346       1799      0.865      0.858      0.919      0.548\n",
      "                 metal         66         73      0.454      0.822      0.724      0.317\n",
      "    periostealreaction        223        351      0.514       0.53      0.547      0.218\n",
      "          pronatorsign         42         42      0.518      0.262      0.429      0.206\n",
      "            softtissue         50         53      0.416      0.245      0.269      0.106\n",
      "                  text       2028       2360      0.961      0.981       0.99      0.738\n",
      "Speed: 0.1ms preprocess, 3.3ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val12\u001b[0m\n",
      "Ultralytics 8.3.50  Python-3.9.13 torch-2.5.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3080 Ti, 12287MiB)\n",
      "YOLO11m summary (fused): 303 layers, 20,036,971 parameters, 0 gradients, 67.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning G:\\Shahadath\\Dataset\\test\\labels.cache... 2033 images, 1 backgrounds, 0 corrupt: 100%|██████████| 2033/2033 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 128/128 [00:15<00:00,  8.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2033       4718      0.747      0.686      0.797      0.557\n",
      "           boneanomaly         23         32      0.642      0.438      0.445      0.249\n",
      "            bonelesion          6          7      0.585      0.571      0.709      0.507\n",
      "           foreignbody          1          1          1          0      0.995      0.796\n",
      "              fracture       1346       1799      0.926      0.945      0.972      0.656\n",
      "                 metal         66         73      0.923      0.988      0.993      0.849\n",
      "    periostealreaction        223        351      0.791      0.677      0.798      0.434\n",
      "          pronatorsign         42         42      0.459      0.952      0.786      0.501\n",
      "            softtissue         50         53      0.425      0.623      0.481      0.267\n",
      "                  text       2028       2360      0.973      0.981      0.991      0.754\n",
      "Speed: 0.1ms preprocess, 3.3ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val13\u001b[0m\n",
      "Ultralytics 8.3.50  Python-3.9.13 torch-2.5.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3080 Ti, 12287MiB)\n",
      "YOLO11m summary (fused): 303 layers, 20,036,971 parameters, 0 gradients, 67.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning G:\\Shahadath\\Dataset\\test\\labels.cache... 2033 images, 1 backgrounds, 0 corrupt: 100%|██████████| 2033/2033 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 128/128 [00:15<00:00,  8.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2033       4718      0.796      0.706      0.816      0.554\n",
      "           boneanomaly         23         32      0.635        0.5      0.466      0.244\n",
      "            bonelesion          6          7       0.78      0.714      0.832      0.569\n",
      "           foreignbody          1          1          1          0      0.995      0.597\n",
      "              fracture       1346       1799      0.925      0.959      0.978      0.671\n",
      "                 metal         66         73       0.97          1      0.995      0.899\n",
      "    periostealreaction        223        351      0.735      0.663      0.763      0.418\n",
      "          pronatorsign         42         42       0.61      0.856      0.771      0.502\n",
      "            softtissue         50         53       0.54      0.679      0.548      0.333\n",
      "                  text       2028       2360      0.973      0.983      0.993      0.756\n",
      "Speed: 0.1ms preprocess, 3.4ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val14\u001b[0m\n",
      "\n",
      "Model                         Precision Recall    mAP@50    mAP@50-95      Params(M) FLOPs(B)  Inference Time (ms)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Model_m_640_32_Adam_best.pt   0.539     0.361     0.449     0.249          20.037    40.074    22.96\n",
      "Model_m_640_16_Adam_best.pt   0.691     0.425     0.492     0.258          20.037    40.074    22.71\n",
      "Model_m_640_SGD_32_best.pt    0.747     0.686     0.797     0.557          20.037    40.074    22.8\n",
      "Model_m_640_16_SGD_best.pt    0.796     0.706     0.816     0.554          20.037    40.074    22.69\n"
     ]
    }
   ],
   "source": [
    "   import time\n",
    "import torch\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Define the models and their paths\n",
    "models_info = [\n",
    "    {\n",
    "        \"name\": \"Model_m_640_32_Adam_best.pt\",\n",
    "        \"weights_path\": \"Model/Model_m_640_32_Adam_best.pt\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Model_m_640_16_Adam_best.pt\",\n",
    "        \"weights_path\": \"Model/Model_m_640_16_Adam_best.pt\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Model_m_640_SGD_32_best.pt\",\n",
    "        \"weights_path\": \"Model/Model_m_640_32_SGD_best.pt\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Model_m_640_16_SGD_best.pt\",\n",
    "        \"weights_path\": \"Model/Model_m_640_16_SGD_best.pt\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Path to data.yaml\n",
    "data_yaml_path = 'data.yaml'\n",
    "\n",
    "# Path to the test images\n",
    "test_images_dir = 'Dataset/test/images'\n",
    "\n",
    "# Get list of image files in the test directory\n",
    "img_files = [f for f in os.listdir(test_images_dir) if f.endswith(('png', 'jpg', 'jpeg'))]\n",
    "num_images = len(img_files)\n",
    "\n",
    "# Initialize a list to store results\n",
    "results = []\n",
    "\n",
    "# Iterate over each model and evaluate\n",
    "for model_info in models_info:\n",
    "    model_name = model_info[\"name\"]\n",
    "    weights_path = model_info[\"weights_path\"]\n",
    "    \n",
    "    # Load the YOLO model\n",
    "    model = YOLO(weights_path)\n",
    "    \n",
    "    # -------------------- Model Evaluation --------------------\n",
    "    # Evaluate the model on the test set\n",
    "    metrics = model.val(data=data_yaml_path, split=\"test\", imgsz=640)\n",
    "\n",
    "    # Extract metrics safely\n",
    "    try:\n",
    "        precision = metrics.box.p.mean()  # Mean Precision\n",
    "        recall = metrics.box.r.mean()     # Mean Recall\n",
    "        map50 = metrics.box.map50.mean()  # Mean mAP@50\n",
    "        map = metrics.box.map.mean()      # Mean mAP@50-95\n",
    "    except AttributeError:\n",
    "        print(f\"Error extracting metrics for {model_name}. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    # -------------------- Inference Time Calculation --------------------\n",
    "    total_time = 0\n",
    "\n",
    "    # Loop through each image file and perform inference\n",
    "    for img_file in img_files:\n",
    "        img_path = os.path.join(test_images_dir, img_file)\n",
    "\n",
    "        # Suppress output from YOLO during inference\n",
    "        with torch.no_grad():\n",
    "            start_time = time.time()\n",
    "            _ = model(img_path, verbose=False)  # Perform inference with verbose=False\n",
    "            inference_time = time.time() - start_time\n",
    "\n",
    "        # Accumulate the inference time in milliseconds\n",
    "        total_time += inference_time * 1000  # Convert to milliseconds\n",
    "\n",
    "    # Calculate the average inference time in milliseconds\n",
    "    average_inference_time = total_time / num_images\n",
    "\n",
    "    # -------------------- Model Parameters and FLOPs --------------------\n",
    "    # Extracting model parameters (in millions)\n",
    "    params = sum(p.numel() for p in model.parameters()) / 1e6  # In millions\n",
    "\n",
    "    # Assuming the model's FLOPs is roughly related to the number of parameters (this is an approximation)\n",
    "    # Using a simple heuristic: FLOPs (billions) ~ Parameters (millions) * 2 (simplified estimate)\n",
    "    flops = params * 2  # This is a rough approximation and may differ based on the architecture\n",
    "\n",
    "    # Append the results for this model\n",
    "    results.append({\n",
    "        \"Model\": model_name,\n",
    "        \"Precision\": round(precision, 3),\n",
    "        \"Recall\": round(recall, 3),\n",
    "        \"mAP@50\": round(map50, 3),\n",
    "        \"mAP@50-95\": round(map, 3),\n",
    "        \"Params(M)\": round(params, 3),\n",
    "        \"FLOPs(B)\": round(flops, 3),\n",
    "        \"Inference Time (ms)\": round(average_inference_time, 2)\n",
    "    })\n",
    "\n",
    "# Print the results table\n",
    "print(f\"\\n{'Model':<30}{'Precision':<10}{'Recall':<10}{'mAP@50':<10}{'mAP@50-95':<15}{'Params(M)':<10}{'FLOPs(B)':<10}{'Inference Time (ms)'}\")\n",
    "print(\"-\" * 100)\n",
    "for result in results:\n",
    "    print(f\"{result['Model']:<30}{result['Precision']:<10}{result['Recall']:<10}{result['mAP@50']:<10}{result['mAP@50-95']:<15}{result['Params(M)']:<10}{result['FLOPs(B)']:<10}{result['Inference Time (ms)']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.50  Python-3.9.13 torch-2.5.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3080 Ti, 12287MiB)\n",
      "YOLO11m summary (fused): 303 layers, 20,036,971 parameters, 0 gradients, 67.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning G:\\Shahadath\\Dataset\\test\\labels.cache... 2033 images, 1 backgrounds, 0 corrupt: 100%|██████████| 2033/2033 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 128/128 [00:15<00:00,  8.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2033       4718      0.796      0.706      0.816      0.554\n",
      "           boneanomaly         23         32      0.635        0.5      0.466      0.244\n",
      "            bonelesion          6          7       0.78      0.714      0.832      0.569\n",
      "           foreignbody          1          1          1          0      0.995      0.597\n",
      "              fracture       1346       1799      0.925      0.959      0.978      0.671\n",
      "                 metal         66         73       0.97          1      0.995      0.899\n",
      "    periostealreaction        223        351      0.735      0.663      0.763      0.418\n",
      "          pronatorsign         42         42       0.61      0.856      0.771      0.502\n",
      "            softtissue         50         53       0.54      0.679      0.548      0.333\n",
      "                  text       2028       2360      0.973      0.983      0.993      0.756\n",
      "Speed: 0.1ms preprocess, 3.3ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val15\u001b[0m\n",
      "Precision: 0.796\n",
      "Recall: 0.706\n",
      "mAP@50: 0.816\n",
      "mAP@50-95: 0.554\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Paths to required files\n",
    "weights_path = 'Model/Model_m_640_16_SGD_best.pt'\n",
    "data_yaml_path = 'data.yaml'\n",
    "\n",
    "# Load the YOLO model\n",
    "model = YOLO(weights_path)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "metrics = model.val(data=data_yaml_path, split=\"test\", batch=16, imgsz=640)\n",
    "\n",
    "# Extract and print metrics\n",
    "precision = metrics.box.p.mean()  # Mean Precision\n",
    "recall = metrics.box.r.mean()     # Mean Recall\n",
    "map50 = metrics.box.map50.mean()  # Mean mAP@50\n",
    "map = metrics.box.map.mean()      # Mean mAP@50-95\n",
    "\n",
    "print(f\"Precision: {round(precision, 3)}\")\n",
    "print(f\"Recall: {round(recall, 3)}\")\n",
    "print(f\"mAP@50: {round(map50, 3)}\")\n",
    "print(f\"mAP@50-95: {round(map, 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.50  Python-3.9.13 torch-2.5.1+cu118 CUDA:0 (NVIDIA GeForce RTX 3080 Ti, 12287MiB)\n",
      "YOLO11m summary (fused): 303 layers, 20,036,971 parameters, 0 gradients, 67.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning G:\\Shahadath\\Dataset\\val\\labels.cache... 4066 images, 3 backgrounds, 0 corrupt: 100%|██████████| 4066/4066 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 255/255 [00:30<00:00,  8.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4066       9426      0.755      0.743      0.788      0.548\n",
      "           boneanomaly         33         46      0.713       0.63      0.712      0.452\n",
      "            bonelesion         13         14      0.826      0.681      0.863      0.548\n",
      "           foreignbody          2          2      0.519        0.5      0.497      0.398\n",
      "              fracture       2709       3606      0.919      0.957      0.978      0.667\n",
      "                 metal        140        163      0.891      0.975      0.986      0.865\n",
      "    periostealreaction        441        693      0.747      0.733      0.772      0.429\n",
      "          pronatorsign        102        102      0.686      0.728      0.824      0.517\n",
      "            softtissue         77         82      0.527        0.5      0.467      0.306\n",
      "                  text       4056       4718      0.969      0.985      0.992      0.753\n",
      "Speed: 0.1ms preprocess, 3.2ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val16\u001b[0m\n",
      "Precision: 0.755\n",
      "Recall: 0.743\n",
      "mAP@50: 0.788\n",
      "mAP@50-95: 0.548\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Paths to required files\n",
    "weights_path = 'Model/Model_m_640_16_SGD_best.pt'\n",
    "data_yaml_path = 'data.yaml'\n",
    "\n",
    "# Load the YOLO model\n",
    "model = YOLO(weights_path)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "metrics = model.val(data=data_yaml_path, split=\"val\", batch=16, imgsz=640)\n",
    "\n",
    "# Extract and print metrics\n",
    "precision = metrics.box.p.mean()  # Mean Precision\n",
    "recall = metrics.box.r.mean()     # Mean Recall\n",
    "map50 = metrics.box.map50.mean()  # Mean mAP@50\n",
    "map = metrics.box.map.mean()      # Mean mAP@50-95\n",
    "\n",
    "print(f\"Precision: {round(precision, 3)}\")\n",
    "print(f\"Recall: {round(recall, 3)}\")\n",
    "print(f\"mAP@50: {round(map50, 3)}\")\n",
    "print(f\"mAP@50-95: {round(map, 3)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
