{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.50  Python-3.9.13 torch-2.6.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3080 Ti, 12287MiB)\n",
      "Setup complete  (16 CPUs, 31.9 GB RAM, 208.0/265.6 GB disk)\n"
     ]
    }
   ],
   "source": [
    "#%pip install git+https://github.com/ultralytics/ultralytics\n",
    "import ultralytics\n",
    "ultralytics.checks()\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the test images\n",
    "test_images_dir = 'Dataset/test/images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to data.yaml\n",
    "data_yaml_path = 'data.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.50  Python-3.9.13 torch-2.6.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3080 Ti, 12287MiB)\n",
      "YOLO11n summary (fused): 238 layers, 2,583,907 parameters, 0 gradients, 6.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning G:\\Shahadath\\Dataset\\test\\labels.cache... 2033 images, 1 backgrounds, 0 corrupt: 100%|██████████| 2033/2033 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 128/128 [00:12<00:00,  9.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2033       4720      0.717      0.532      0.544      0.346\n",
      "           boneanomaly         16         19      0.289      0.211      0.178     0.0868\n",
      "            bonelesion          8          8      0.769      0.125      0.171     0.0864\n",
      "           foreignbody          1          1          1          0          0          0\n",
      "              fracture       1351       1784      0.856      0.886      0.932      0.567\n",
      "                 metal         74         85       0.83      0.941      0.952      0.805\n",
      "    periostealreaction        230        352      0.584      0.639      0.637      0.291\n",
      "          pronatorsign         47         47       0.72      0.438      0.587      0.325\n",
      "            softtissue         38         39      0.447      0.564      0.446      0.211\n",
      "                  text       2029       2385      0.962      0.982      0.992      0.742\n",
      "Speed: 0.1ms preprocess, 1.5ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val148\u001b[0m\n",
      "Ultralytics 8.3.50  Python-3.9.13 torch-2.6.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3080 Ti, 12287MiB)\n",
      "YOLO11s summary (fused): 238 layers, 9,416,283 parameters, 0 gradients, 21.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning G:\\Shahadath\\Dataset\\test\\labels.cache... 2033 images, 1 backgrounds, 0 corrupt: 100%|██████████| 2033/2033 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 128/128 [00:11<00:00, 10.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2033       4720       0.78      0.556      0.692       0.44\n",
      "           boneanomaly         16         19      0.435      0.158       0.17     0.0902\n",
      "            bonelesion          8          8      0.868       0.25      0.305      0.205\n",
      "           foreignbody          1          1          1          0      0.995      0.502\n",
      "              fracture       1351       1784      0.892      0.918      0.956      0.606\n",
      "                 metal         74         85      0.933      0.965      0.974      0.846\n",
      "    periostealreaction        230        352      0.722      0.641      0.736      0.371\n",
      "          pronatorsign         47         47      0.566      0.702      0.709      0.411\n",
      "            softtissue         38         39      0.632      0.385      0.386      0.179\n",
      "                  text       2029       2385      0.971      0.985      0.993      0.748\n",
      "Speed: 0.1ms preprocess, 1.7ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val149\u001b[0m\n",
      "Ultralytics 8.3.50  Python-3.9.13 torch-2.6.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3080 Ti, 12287MiB)\n",
      "YOLO11m summary (fused): 303 layers, 20,036,971 parameters, 0 gradients, 67.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning G:\\Shahadath\\Dataset\\test\\labels.cache... 2033 images, 1 backgrounds, 0 corrupt: 100%|██████████| 2033/2033 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 128/128 [00:15<00:00,  8.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2033       4720      0.843       0.68      0.836       0.57\n",
      "           boneanomaly         16         19       0.81      0.526      0.615      0.431\n",
      "            bonelesion          8          8      0.926      0.625      0.735      0.463\n",
      "           foreignbody          1          1          1          0      0.995      0.597\n",
      "              fracture       1351       1784      0.931       0.95      0.977      0.666\n",
      "                 metal         74         85       0.96          1      0.995      0.884\n",
      "    periostealreaction        230        352      0.752      0.699      0.775      0.439\n",
      "          pronatorsign         47         47      0.699      0.745      0.818      0.508\n",
      "            softtissue         38         39      0.533       0.59      0.619      0.392\n",
      "                  text       2029       2385      0.976      0.987      0.994      0.755\n",
      "Speed: 0.1ms preprocess, 3.3ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val150\u001b[0m\n",
      "\n",
      "Model                         Precision Recall    mAP@50    mAP@50-95      Params(M) FLOPs(B)  Inference Time (ms)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Model_N_best.pt.pt            0.717     0.532     0.544     0.346          2.584     5.168     20.48\n",
      "Model_S_best.pt.pt            0.78      0.556     0.692     0.44           9.416     18.833    20.12\n",
      "Model_M_best.pt               0.843     0.68      0.836     0.57           20.037    40.074    22.23\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Define the models and their paths\n",
    "models_info = [\n",
    "    {\n",
    "        \"name\": \"Model_N_best.pt.pt\",\n",
    "        \"weights_path\": \"Model/Model_N_best.pt\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Model_S_best.pt.pt\",\n",
    "        \"weights_path\": \"Model/Model_S_best.pt\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Model_M_best.pt\",\n",
    "        \"weights_path\": \"Model/Model_M_best.pt\"\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "# # Path to data.yaml\n",
    "# data_yaml_path = 'data.yaml'\n",
    "\n",
    "\n",
    "# Get list of image files in the test directory\n",
    "img_files = [f for f in os.listdir(test_images_dir) if f.endswith(('png', 'jpg', 'jpeg'))]\n",
    "num_images = len(img_files)\n",
    "\n",
    "# Initialize a list to store results\n",
    "results = []\n",
    "\n",
    "# Iterate over each model and evaluate\n",
    "for model_info in models_info:\n",
    "    model_name = model_info[\"name\"]\n",
    "    weights_path = model_info[\"weights_path\"]\n",
    "    \n",
    "    # Load the YOLO model\n",
    "    model = YOLO(weights_path)\n",
    "    \n",
    "    # -------------------- Model Evaluation --------------------\n",
    "    # Evaluate the model on the test set\n",
    "    metrics = model.val(data=data_yaml_path, split=\"test\", batch=16, imgsz=640)\n",
    "\n",
    "    # Extract metrics safely\n",
    "    try:\n",
    "        precision = metrics.box.p.mean()  # Mean Precision\n",
    "        recall = metrics.box.r.mean()     # Mean Recall\n",
    "        map50 = metrics.box.map50.mean()  # Mean mAP@50\n",
    "        map = metrics.box.map.mean()      # Mean mAP@50-95\n",
    "    except AttributeError:\n",
    "        print(f\"Error extracting metrics for {model_name}. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    # -------------------- Inference Time Calculation --------------------\n",
    "    total_time = 0\n",
    "\n",
    "    # Loop through each image file and perform inference\n",
    "    for img_file in img_files:\n",
    "        img_path = os.path.join(test_images_dir, img_file)\n",
    "\n",
    "        # Suppress output from YOLO during inference\n",
    "        with torch.no_grad():\n",
    "            start_time = time.time()\n",
    "            _ = model(img_path, verbose=False)  # Perform inference with verbose=False\n",
    "            inference_time = time.time() - start_time\n",
    "\n",
    "        # Accumulate the inference time in milliseconds\n",
    "        total_time += inference_time * 1000  # Convert to milliseconds\n",
    "\n",
    "    # Calculate the average inference time in milliseconds\n",
    "    average_inference_time = total_time / num_images\n",
    "\n",
    "    # -------------------- Model Parameters and FLOPs --------------------\n",
    "    # Extracting model parameters (in millions)\n",
    "    params = sum(p.numel() for p in model.parameters()) / 1e6  # In millions\n",
    "\n",
    "    # Assuming the model's FLOPs is roughly related to the number of parameters (this is an approximation)\n",
    "    # Using a simple heuristic: FLOPs (billions) ~ Parameters (millions) * 2 (simplified estimate)\n",
    "    flops = params * 2  # This is a rough approximation and may differ based on the architecture\n",
    "\n",
    "    # Append the results for this model\n",
    "    results.append({\n",
    "        \"Model\": model_name,\n",
    "        \"Precision\": round(precision, 3),\n",
    "        \"Recall\": round(recall, 3),\n",
    "        \"mAP@50\": round(map50, 3),\n",
    "        \"mAP@50-95\": round(map, 3),\n",
    "        \"Params(M)\": round(params, 3),\n",
    "        \"FLOPs(B)\": round(flops, 3),\n",
    "        \"Inference Time (ms)\": round(average_inference_time, 2)\n",
    "    })\n",
    "\n",
    "# Print the results table\n",
    "print(f\"\\n{'Model':<30}{'Precision':<10}{'Recall':<10}{'mAP@50':<10}{'mAP@50-95':<15}{'Params(M)':<10}{'FLOPs(B)':<10}{'Inference Time (ms)'}\")\n",
    "print(\"-\" * 100)\n",
    "for result in results:\n",
    "    print(f\"{result['Model']:<30}{result['Precision']:<10}{result['Recall']:<10}{result['mAP@50']:<10}{result['mAP@50-95']:<15}{result['Params(M)']:<10}{result['FLOPs(B)']:<10}{result['Inference Time (ms)']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.50  Python-3.9.13 torch-2.6.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3080 Ti, 12287MiB)\n",
      "YOLO11m summary (fused): 303 layers, 20,036,971 parameters, 0 gradients, 67.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning G:\\Shahadath\\Dataset\\test\\labels.cache... 2033 images, 1 backgrounds, 0 corrupt: 100%|██████████| 2033/2033 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 128/128 [00:15<00:00,  8.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2033       4720      0.441      0.421      0.418      0.233\n",
      "           boneanomaly         16         19          0          0     0.0145    0.00563\n",
      "            bonelesion          8          8          1          0      0.126     0.0881\n",
      "           foreignbody          1          1          0          0          0          0\n",
      "              fracture       1351       1784       0.76      0.888      0.912      0.541\n",
      "                 metal         74         85      0.415      0.812      0.691      0.291\n",
      "    periostealreaction        230        352      0.346      0.716      0.521      0.208\n",
      "          pronatorsign         47         47      0.416      0.362      0.421       0.19\n",
      "            softtissue         38         39     0.0859     0.0256     0.0834     0.0369\n",
      "                  text       2029       2385      0.951      0.983      0.991      0.737\n",
      "Speed: 0.1ms preprocess, 3.4ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val151\u001b[0m\n",
      "Ultralytics 8.3.50  Python-3.9.13 torch-2.6.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3080 Ti, 12287MiB)\n",
      "YOLO11m summary (fused): 303 layers, 20,036,971 parameters, 0 gradients, 67.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning G:\\Shahadath\\Dataset\\test\\labels.cache... 2033 images, 1 backgrounds, 0 corrupt: 100%|██████████| 2033/2033 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 128/128 [00:15<00:00,  8.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2033       4720      0.759      0.398      0.447      0.243\n",
      "           boneanomaly         16         19          1          0     0.0353      0.012\n",
      "            bonelesion          8          8          1          0      0.126     0.0634\n",
      "           foreignbody          1          1          1          0     0.0553     0.0276\n",
      "              fracture       1351       1784      0.881      0.856       0.92      0.549\n",
      "                 metal         74         85      0.492      0.776      0.681      0.269\n",
      "    periostealreaction        230        352       0.57       0.56      0.564       0.23\n",
      "          pronatorsign         47         47      0.502      0.258      0.445      0.208\n",
      "            softtissue         38         39      0.425      0.152      0.209     0.0946\n",
      "                  text       2029       2385      0.964      0.983      0.992      0.738\n",
      "Speed: 0.1ms preprocess, 3.4ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val152\u001b[0m\n",
      "Ultralytics 8.3.50  Python-3.9.13 torch-2.6.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3080 Ti, 12287MiB)\n",
      "YOLO11m summary (fused): 303 layers, 20,036,971 parameters, 0 gradients, 67.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning G:\\Shahadath\\Dataset\\test\\labels.cache... 2033 images, 1 backgrounds, 0 corrupt: 100%|██████████| 2033/2033 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 128/128 [00:15<00:00,  8.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2033       4720      0.794      0.661      0.792      0.547\n",
      "           boneanomaly         16         19      0.659      0.474        0.5      0.276\n",
      "            bonelesion          8          8          1      0.447      0.707      0.468\n",
      "           foreignbody          1          1          1          0      0.995      0.796\n",
      "              fracture       1351       1784      0.929      0.948      0.977      0.655\n",
      "                 metal         74         85      0.932      0.953      0.984      0.847\n",
      "    periostealreaction        230        352      0.779      0.679      0.782      0.448\n",
      "          pronatorsign         47         47      0.478      0.872      0.782      0.475\n",
      "            softtissue         38         39      0.396       0.59      0.403      0.204\n",
      "                  text       2029       2385      0.975      0.987      0.993      0.756\n",
      "Speed: 0.1ms preprocess, 3.3ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val153\u001b[0m\n",
      "Ultralytics 8.3.50  Python-3.9.13 torch-2.6.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3080 Ti, 12287MiB)\n",
      "YOLO11m summary (fused): 303 layers, 20,036,971 parameters, 0 gradients, 67.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning G:\\Shahadath\\Dataset\\test\\labels.cache... 2033 images, 1 backgrounds, 0 corrupt: 100%|██████████| 2033/2033 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 128/128 [00:15<00:00,  8.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2033       4720      0.843       0.68      0.836       0.57\n",
      "           boneanomaly         16         19       0.81      0.526      0.615      0.431\n",
      "            bonelesion          8          8      0.926      0.625      0.735      0.463\n",
      "           foreignbody          1          1          1          0      0.995      0.597\n",
      "              fracture       1351       1784      0.931       0.95      0.977      0.666\n",
      "                 metal         74         85       0.96          1      0.995      0.884\n",
      "    periostealreaction        230        352      0.752      0.699      0.775      0.439\n",
      "          pronatorsign         47         47      0.699      0.745      0.818      0.508\n",
      "            softtissue         38         39      0.533       0.59      0.619      0.392\n",
      "                  text       2029       2385      0.976      0.987      0.994      0.755\n",
      "Speed: 0.1ms preprocess, 3.3ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val154\u001b[0m\n",
      "\n",
      "Model                         Precision Recall    mAP@50    mAP@50-95      Params(M) FLOPs(B)  Inference Time (ms)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Model_m_640_32_Adam_best.pt   0.441     0.421     0.418     0.233          20.037    40.074    22.18\n",
      "Model_m_640_16_Adam_best.pt   0.759     0.398     0.447     0.243          20.037    40.074    22.06\n",
      "Model_m_640_SGD_32_best.pt    0.794     0.661     0.792     0.547          20.037    40.074    22.18\n",
      "Model_m_640_16_SGD_best.pt    0.843     0.68      0.836     0.57           20.037    40.074    22.1\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Define the models and their paths\n",
    "models_info = [\n",
    "    {\n",
    "        \"name\": \"Model_m_640_32_Adam_best.pt\",\n",
    "        \"weights_path\": \"Model/Model_m_640_32_Adam_best.pt\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Model_m_640_16_Adam_best.pt\",\n",
    "        \"weights_path\": \"Model/Model_m_640_16_Adam_best.pt\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Model_m_640_SGD_32_best.pt\",\n",
    "        \"weights_path\": \"Model/Model_m_640_32_SGD_best.pt\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Model_m_640_16_SGD_best.pt\",\n",
    "        \"weights_path\": \"Model/Model_m_640_16_SGD_best.pt\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# # Path to data.yaml\n",
    "# data_yaml_path = 'data.yaml'\n",
    "\n",
    "# # Path to the test images\n",
    "# test_images_dir = 'Dataset/test/images'\n",
    "\n",
    "# Get list of image files in the test directory\n",
    "img_files = [f for f in os.listdir(test_images_dir) if f.endswith(('png', 'jpg', 'jpeg'))]\n",
    "num_images = len(img_files)\n",
    "\n",
    "# Initialize a list to store results\n",
    "results = []\n",
    "\n",
    "# Iterate over each model and evaluate\n",
    "for model_info in models_info:\n",
    "    model_name = model_info[\"name\"]\n",
    "    weights_path = model_info[\"weights_path\"]\n",
    "    \n",
    "    # Load the YOLO model\n",
    "    model = YOLO(weights_path)\n",
    "    \n",
    "    # -------------------- Model Evaluation --------------------\n",
    "    # Evaluate the model on the test set\n",
    "    metrics = model.val(data=data_yaml_path, split=\"test\", imgsz=640)\n",
    "\n",
    "    # Extract metrics safely\n",
    "    try:\n",
    "        precision = metrics.box.p.mean()  # Mean Precision\n",
    "        recall = metrics.box.r.mean()     # Mean Recall\n",
    "        map50 = metrics.box.map50.mean()  # Mean mAP@50\n",
    "        map = metrics.box.map.mean()      # Mean mAP@50-95\n",
    "    except AttributeError:\n",
    "        print(f\"Error extracting metrics for {model_name}. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    # -------------------- Inference Time Calculation --------------------\n",
    "    total_time = 0\n",
    "\n",
    "    # Loop through each image file and perform inference\n",
    "    for img_file in img_files:\n",
    "        img_path = os.path.join(test_images_dir, img_file)\n",
    "\n",
    "        # Suppress output from YOLO during inference\n",
    "        with torch.no_grad():\n",
    "            start_time = time.time()\n",
    "            _ = model(img_path, verbose=False)  # Perform inference with verbose=False\n",
    "            inference_time = time.time() - start_time\n",
    "\n",
    "        # Accumulate the inference time in milliseconds\n",
    "        total_time += inference_time * 1000  # Convert to milliseconds\n",
    "\n",
    "    # Calculate the average inference time in milliseconds\n",
    "    average_inference_time = total_time / num_images\n",
    "\n",
    "    # -------------------- Model Parameters and FLOPs --------------------\n",
    "    # Extracting model parameters (in millions)\n",
    "    params = sum(p.numel() for p in model.parameters()) / 1e6  # In millions\n",
    "\n",
    "    # Assuming the model's FLOPs is roughly related to the number of parameters (this is an approximation)\n",
    "    # Using a simple heuristic: FLOPs (billions) ~ Parameters (millions) * 2 (simplified estimate)\n",
    "    flops = params * 2  # This is a rough approximation and may differ based on the architecture\n",
    "\n",
    "    # Append the results for this model\n",
    "    results.append({\n",
    "        \"Model\": model_name,\n",
    "        \"Precision\": round(precision, 3),\n",
    "        \"Recall\": round(recall, 3),\n",
    "        \"mAP@50\": round(map50, 3),\n",
    "        \"mAP@50-95\": round(map, 3),\n",
    "        \"Params(M)\": round(params, 3),\n",
    "        \"FLOPs(B)\": round(flops, 3),\n",
    "        \"Inference Time (ms)\": round(average_inference_time, 2)\n",
    "    })\n",
    "\n",
    "# Print the results table\n",
    "print(f\"\\n{'Model':<30}{'Precision':<10}{'Recall':<10}{'mAP@50':<10}{'mAP@50-95':<15}{'Params(M)':<10}{'FLOPs(B)':<10}{'Inference Time (ms)'}\")\n",
    "print(\"-\" * 100)\n",
    "for result in results:\n",
    "    print(f\"{result['Model']:<30}{result['Precision']:<10}{result['Recall']:<10}{result['mAP@50']:<10}{result['mAP@50-95']:<15}{result['Params(M)']:<10}{result['FLOPs(B)']:<10}{result['Inference Time (ms)']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.50  Python-3.9.13 torch-2.6.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3080 Ti, 12287MiB)\n",
      "YOLO11m summary (fused): 303 layers, 20,036,971 parameters, 0 gradients, 67.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning G:\\Shahadath\\Dataset\\test\\labels.cache... 2033 images, 1 backgrounds, 0 corrupt: 100%|██████████| 2033/2033 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 128/128 [00:14<00:00,  8.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2033       4720      0.843       0.68      0.836       0.57\n",
      "           boneanomaly         16         19       0.81      0.526      0.615      0.431\n",
      "            bonelesion          8          8      0.926      0.625      0.735      0.463\n",
      "           foreignbody          1          1          1          0      0.995      0.597\n",
      "              fracture       1351       1784      0.931       0.95      0.977      0.666\n",
      "                 metal         74         85       0.96          1      0.995      0.884\n",
      "    periostealreaction        230        352      0.752      0.699      0.775      0.439\n",
      "          pronatorsign         47         47      0.699      0.745      0.818      0.508\n",
      "            softtissue         38         39      0.533       0.59      0.619      0.392\n",
      "                  text       2029       2385      0.976      0.987      0.994      0.755\n",
      "Speed: 0.1ms preprocess, 3.3ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val156\u001b[0m\n",
      "Precision: 0.843\n",
      "Recall: 0.68\n",
      "mAP@50: 0.836\n",
      "mAP@50-95: 0.57\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Paths to required files\n",
    "weights_path = 'Model/Model_m_640_16_SGD_best.pt'\n",
    "# data_yaml_path = 'data.yaml'\n",
    "\n",
    "# Load the YOLO model\n",
    "model = YOLO(weights_path)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "metrics = model.val(data=data_yaml_path, split=\"test\", batch=16, imgsz=640)\n",
    "\n",
    "# Extract and print metrics\n",
    "precision = metrics.box.p.mean()  # Mean Precision\n",
    "recall = metrics.box.r.mean()     # Mean Recall\n",
    "map50 = metrics.box.map50.mean()  # Mean mAP@50\n",
    "map = metrics.box.map.mean()      # Mean mAP@50-95\n",
    "\n",
    "print(f\"Precision: {round(precision, 3)}\")\n",
    "print(f\"Recall: {round(recall, 3)}\")\n",
    "print(f\"mAP@50: {round(map50, 3)}\")\n",
    "print(f\"mAP@50-95: {round(map, 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.50  Python-3.9.13 torch-2.6.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3080 Ti, 12287MiB)\n",
      "YOLO11m summary (fused): 303 layers, 20,036,971 parameters, 0 gradients, 67.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning G:\\Shahadath\\Dataset\\val\\labels.cache... 4066 images, 4 backgrounds, 0 corrupt: 100%|██████████| 4066/4066 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 255/255 [00:56<00:00,  4.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4066       9500      0.846       0.74      0.829      0.585\n",
      "           boneanomaly         46         71      0.712      0.522      0.615      0.379\n",
      "            bonelesion          9          9      0.859      0.556      0.764      0.472\n",
      "           foreignbody          4          4      0.877          1      0.995      0.837\n",
      "              fracture       2736       3653      0.954       0.93       0.98      0.664\n",
      "                 metal        128        148       0.96      0.966      0.991       0.88\n",
      "    periostealreaction        421        660      0.842      0.617      0.776      0.434\n",
      "          pronatorsign        125        126      0.818      0.611      0.791      0.495\n",
      "            softtissue         72         77      0.615      0.481      0.558      0.344\n",
      "                  text       4055       4752       0.98      0.975      0.993      0.756\n",
      "Speed: 0.1ms preprocess, 7.0ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val158\u001b[0m\n",
      "Precision: 0.846\n",
      "Recall: 0.74\n",
      "mAP@50: 0.829\n",
      "mAP@50-95: 0.585\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Paths to required files\n",
    "weights_path = 'Model/Model_m_640_16_SGD_best.pt'\n",
    "# data_yaml_path = 'data.yaml'\n",
    "\n",
    "# Load the YOLO model\n",
    "model = YOLO(weights_path)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "metrics = model.val(data=data_yaml_path, split=\"val\", batch=16, imgsz=640)\n",
    "\n",
    "# Extract and print metrics\n",
    "precision = metrics.box.p.mean()  # Mean Precision\n",
    "recall = metrics.box.r.mean()     # Mean Recall\n",
    "map50 = metrics.box.map50.mean()  # Mean mAP@50\n",
    "map = metrics.box.map.mean()      # Mean mAP@50-95\n",
    "\n",
    "print(f\"Precision: {round(precision, 3)}\")\n",
    "print(f\"Recall: {round(recall, 3)}\")\n",
    "print(f\"mAP@50: {round(map50, 3)}\")\n",
    "print(f\"mAP@50-95: {round(map, 3)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
